{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_csv(path):\n",
    "    \"\"\"Reads xml files with information on class name and bounding\n",
    "    box and write them to a csv file\n",
    "    \n",
    "    Arguments:\n",
    "        path = str, path where xml files are stored\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inizialize class names vector and xml valies\n",
    "    classes_names = []\n",
    "    xml_values = []\n",
    "    \n",
    "    for xml_file in glob.glob(path + \"/*.xml\"):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for member in root.findall(\"object\"):\n",
    "            classes_names.append(member[0].text)\n",
    "            xml_values.append((\n",
    "                root.find(\"filename\").text,\n",
    "                int(root.find(\"size\")[0].text),\n",
    "                int(root.find(\"size\")[1].text),\n",
    "                member[0].text,\n",
    "                int(member.find('bndbox').find('xmin').text),\n",
    "                int(member.find('bndbox').find('ymin').text),\n",
    "                int(member.find('bndbox').find('xmax').text),\n",
    "                int(member.find('bndbox').find('ymax').text),\n",
    "            ))\n",
    "            \n",
    "    column_name = [\"filename\", \"width\", \"height\", \"class\",\n",
    "                   \"xmin\", \"ymin\", \"xmax\", \"ymax\",]\n",
    "    \n",
    "    xml_df = pd.DataFrame(xml_values, columns=column_name)\n",
    "    classes_names = list(set(classes_names))\n",
    "    classes_names.sort()\n",
    "    return xml_df, classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/images/train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df, classes_names = convert_xml_to_csv(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"item {\\n    id: 1\\n    name: 'f1_car'\\n}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_classes_protobuf(classes_names):\n",
    "    \"\"\"Create a protocol buffer file storing\n",
    "    the name of the classes. This is used by the\n",
    "    object detection API\n",
    "    \n",
    "    Arguments:\n",
    "        classes_names = list, classes names\n",
    "    \"\"\"\n",
    "    \n",
    "    pbtxt_content = \"\"\n",
    "    \n",
    "    for i, class_name in enumerate(classes_names):\n",
    "            pbtxt_content = (\n",
    "                pbtxt_content\n",
    "                + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(\n",
    "                    i + 1, class_name\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return pbtxt_content.strip()\n",
    "\n",
    "create_classes_protobuf(classes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"item {\\n    id: 1\\n    name: 'f1_car'\\n}\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_path = 'label_map.pbtxt'\n",
    "\n",
    "pbtxt_content = \"\"\n",
    "for i, class_name in enumerate(classes_names):\n",
    "            pbtxt_content = (\n",
    "                pbtxt_content\n",
    "                + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(\n",
    "                    i + 1, class_name\n",
    "                )\n",
    "            )\n",
    "        \n",
    "pbtxt_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbtxt_content = pbtxt_content.strip()\n",
    "pbtxt_content\n",
    "\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    f.write(pbtxt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df, classes_names = xml_to_csv(args.inputDir)\n",
    "    xml_df.to_csv(args.outputFile, index=None)\n",
    "    print(\"Successfully converted xml to csv.\")\n",
    "    if args.labelMapDir:\n",
    "        os.makedirs(args.labelMapDir, exist_ok=True)\n",
    "        label_map_path = os.path.join(args.labelMapDir, \"label_map.pbtxt\")\n",
    "        print(\"Generate `{}`\".format(label_map_path))\n",
    "\n",
    "        # Create the `label_map.pbtxt` file\n",
    "        pbtxt_content = \"\"\n",
    "        for i, class_name in enumerate(classes_names):\n",
    "            pbtxt_content = (\n",
    "                pbtxt_content\n",
    "                + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(\n",
    "                    i + 1, class_name\n",
    "                )\n",
    "            )\n",
    "        pbtxt_content = pbtxt_content.strip()\n",
    "        with open(label_map_path, \"w\") as f:\n",
    "            f.write(pbtxt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\n",
    "# Usage:\n",
    "# # Create train data:\n",
    "# python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/train -o [PATH_TO_ANNOTATIONS_FOLDER]/train_labels.csv\n",
    "\n",
    "# # Create test data:\n",
    "# python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/test -o [PATH_TO_ANNOTATIONS_FOLDER]/test_labels.csv\n",
    "# \"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def xml_to_csv(path):\n",
    "    \"\"\"Iterates through all .xml files (generated by labelImg) in a given \n",
    "    directory and combines them in a single Pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    path : {str}\n",
    "        The path containing the .xml files\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        The produced dataframe\n",
    "    \"\"\"\n",
    "    classes_names = []\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + \"/*.xml\"):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall(\"object\"):\n",
    "            classes_names.append(member[0].text)\n",
    "            value = (\n",
    "                root.find(\"filename\").text,\n",
    "                int(root.find(\"size\")[0].text),\n",
    "                int(root.find(\"size\")[1].text),\n",
    "                member[0].text,\n",
    "                int(member.find('bndbox').find('xmin').text),\n",
    "                int(member.find('bndbox').find('ymin').text),\n",
    "                int(member.find('bndbox').find('xmax').text),\n",
    "                int(member.find('bndbox').find('ymax').text),\n",
    "            )\n",
    "            xml_list.append(value)\n",
    "    column_name = [\n",
    "        \"filename\",\n",
    "        \"width\",\n",
    "        \"height\",\n",
    "        \"class\",\n",
    "        \"xmin\",\n",
    "        \"ymin\",\n",
    "        \"xmax\",\n",
    "        \"ymax\",\n",
    "    ]\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    classes_names = list(set(classes_names))\n",
    "    classes_names.sort()\n",
    "    return xml_df, classes_names\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initiate argument parser\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Sample TensorFlow XML-to-CSV converter\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--inputDir\",\n",
    "        help=\"Path to the folder where the input .xml files are stored\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\", \"--outputFile\", help=\"Name of output .csv file (including path)\", type=str\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-l\",\n",
    "        \"--labelMapDir\",\n",
    "        help=\"Directory path to save label_map.pbtxt file is specified.\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.inputDir is None:\n",
    "        args.inputDir = os.getcwd()\n",
    "    if args.outputFile is None:\n",
    "        args.outputFile = args.inputDir + \"/labels.csv\"\n",
    "\n",
    "    assert os.path.isdir(args.inputDir)\n",
    "    os.makedirs(os.path.dirname(args.outputFile), exist_ok=True)\n",
    "    xml_df, classes_names = xml_to_csv(args.inputDir)\n",
    "    xml_df.to_csv(args.outputFile, index=None)\n",
    "    print(\"Successfully converted xml to csv.\")\n",
    "    if args.labelMapDir:\n",
    "        os.makedirs(args.labelMapDir, exist_ok=True)\n",
    "        label_map_path = os.path.join(args.labelMapDir, \"label_map.pbtxt\")\n",
    "        print(\"Generate `{}`\".format(label_map_path))\n",
    "\n",
    "        # Create the `label_map.pbtxt` file\n",
    "        pbtxt_content = \"\"\n",
    "        for i, class_name in enumerate(classes_names):\n",
    "            pbtxt_content = (\n",
    "                pbtxt_content\n",
    "                + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(\n",
    "                    i + 1, class_name\n",
    "                )\n",
    "            )\n",
    "        pbtxt_content = pbtxt_content.strip()\n",
    "        with open(label_map_path, \"w\") as f:\n",
    "            f.write(pbtxt_content)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usage:\n",
    "\n",
    "# Create train data:\n",
    "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record <PATH_TO_ANNOTATIONS_FOLDER>/label_map.pbtxt\n",
    "\n",
    "# Create test data:\n",
    "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record  --label_map <PATH_TO_ANNOTATIONS_FOLDER>/label_map.pbtxt\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../models/research\")\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string(\"csv_input\", \"\", \"Path to the CSV input\")\n",
    "flags.DEFINE_string(\"output_path\", \"\", \"Path to output TFRecord\")\n",
    "flags.DEFINE_string(\n",
    "    \"label_map\",\n",
    "    \"\",\n",
    "    \"Path to the `label_map.pbtxt` contains the <class_name>:<class_index> pairs generated by `xml_to_csv.py` or manually.\",\n",
    ")\n",
    "# if your image has more labels input them as\n",
    "# flags.DEFINE_string('label0', '', 'Name of class[0] label')\n",
    "# flags.DEFINE_string('label1', '', 'Name of class[1] label')\n",
    "# and so on.\n",
    "flags.DEFINE_string(\"img_path\", \"\", \"Path to images\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple(\"data\", [\"filename\", \"object\"])\n",
    "    gb = df.groupby(group)\n",
    "    return [\n",
    "        data(filename, gb.get_group(x))\n",
    "        for filename, x in zip(gb.groups.keys(), gb.groups)\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path, label_map):\n",
    "    with tf.gfile.GFile(os.path.join(path, \"{}\".format(group.filename)), \"rb\") as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode(\"utf8\")\n",
    "    image_format = b\"jpg\"\n",
    "    # check if the image format is matching with your images.\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row[\"xmin\"] / width)\n",
    "        xmaxs.append(row[\"xmax\"] / width)\n",
    "        ymins.append(row[\"ymin\"] / height)\n",
    "        ymaxs.append(row[\"ymax\"] / height)\n",
    "        classes_text.append(row[\"class\"].encode(\"utf8\"))\n",
    "        class_index = label_map.get(row[\"class\"])\n",
    "        assert (\n",
    "            class_index is not None\n",
    "        ), \"class label: `{}` not found in label_map: {}\".format(\n",
    "            row[\"class\"], label_map\n",
    "        )\n",
    "        classes.append(class_index)\n",
    "\n",
    "    tf_example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image/height\": dataset_util.int64_feature(height),\n",
    "                \"image/width\": dataset_util.int64_feature(width),\n",
    "                \"image/filename\": dataset_util.bytes_feature(filename),\n",
    "                \"image/source_id\": dataset_util.bytes_feature(filename),\n",
    "                \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
    "                \"image/format\": dataset_util.bytes_feature(image_format),\n",
    "                \"image/object/bbox/xmin\": dataset_util.float_list_feature(xmins),\n",
    "                \"image/object/bbox/xmax\": dataset_util.float_list_feature(xmaxs),\n",
    "                \"image/object/bbox/ymin\": dataset_util.float_list_feature(ymins),\n",
    "                \"image/object/bbox/ymax\": dataset_util.float_list_feature(ymaxs),\n",
    "                \"image/object/class/text\": dataset_util.bytes_list_feature(\n",
    "                    classes_text\n",
    "                ),\n",
    "                \"image/object/class/label\": dataset_util.int64_list_feature(classes),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
    "    path = os.path.join(os.getcwd(), FLAGS.img_path)\n",
    "    examples = pd.read_csv(FLAGS.csv_input)\n",
    "\n",
    "    # Load the `label_map` from pbtxt file.\n",
    "    from object_detection.utils import label_map_util\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(FLAGS.label_map)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True\n",
    "    )\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    label_map = {}\n",
    "    for k, v in category_index.items():\n",
    "        label_map[v.get(\"name\")] = v.get(\"id\")\n",
    "\n",
    "    grouped = split(examples, \"filename\")\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path, label_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
    "    print(\"Successfully created the TFRecords: {}\".format(output_path))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\"../../models/research\")\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(\"data/train.record\")\n",
    "path = os.path.join(\"data/images/train\")\n",
    "examples = xml_df\n",
    "\n",
    "label_map = label_map_util.load_labelmap('label_map.pbtxt')\n",
    "\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True\n",
    "    )\n",
    "\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "label_map = {}\n",
    "for k, v in category_index.items():\n",
    "    label_map[v.get(\"name\")] = v.get(\"id\")\n",
    "    \n",
    "grouped = split(examples, \"filename\")\n",
    "\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group, path, label_map)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"data/images/train\"\n",
    "images_xml_df = xml_df\n",
    "label_map_path = 'label_map.pbtxt'\n",
    "output_path = \"data/train2.record\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecords created in data/train2.record\n"
     ]
    }
   ],
   "source": [
    "TfRecordConverter(images_path, images_xml_df, label_map_path, output_path).create_tfrecord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfRecordConverter(object):\n",
    "    \n",
    "    def __init__(self, images_path, images_xml_df, label_map_path, output_path):\n",
    "        \"\"\"Class to convert images and annotations to XML\n",
    "        \n",
    "        Arguments:\n",
    "            images_path = str, path where the images to convert are stored\n",
    "            images_xml_df = pandas df with reference to files and annotations\n",
    "                created with the utilis to converto_xml_to_csv function\n",
    "            label_map_path = str, path where a protobuf label map file is stored\n",
    "            output_path = str, path where tfr records are stored   \n",
    "        \"\"\"\n",
    "        self.images_path = images_path\n",
    "        self.xml_df = images_xml_df\n",
    "        self.label_map_path = label_map_path\n",
    "        self.output_path = output_path\n",
    "        \n",
    "    def create_tfrecord(self):\n",
    "        \"\"\"Main function to create TF Records\"\"\"\n",
    "        \n",
    "        # Inizialize the TFR Record Writer\n",
    "        writer = tf.python_io.TFRecordWriter(self.output_path)\n",
    "        path = os.path.join(self.images_path)\n",
    "        \n",
    "        # Create label map dictionary\n",
    "        label_map = label_map_util.load_labelmap(self.label_map_path)\n",
    "\n",
    "        categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "\n",
    "        category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "        label_map = {}\n",
    "        for k, v in category_index.items():\n",
    "            label_map[v.get(\"name\")] = v.get(\"id\")\n",
    "        \n",
    "        # Create groups\n",
    "        grouped = self._split()\n",
    "        \n",
    "        # Create TFR Record\n",
    "        for group in grouped:\n",
    "            tf_example = self._create_tf_example(group, label_map)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "        writer.close()\n",
    "        print('TFRecords created in {}'.format(self.output_path))\n",
    "        \n",
    "    \n",
    "    def _split(self):\n",
    "        \"\"\"Convenience function that input a pandas \n",
    "        dataframe of xml annotations related to an image\n",
    "        and split into several smaller dataframe for each image.\n",
    "        \n",
    "        To create the xml use the convert_xml_to_csv in the \n",
    "        utils package.\n",
    "        \n",
    "        Arguments:\n",
    "            df = pandas dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        data = namedtuple(\"data\", [\"filename\", \"object\"])\n",
    "        gb = self.xml_df.groupby(\"filename\")\n",
    "        \n",
    "        groups = [\n",
    "            data(filename, gb.get_group(x))\n",
    "            for filename, x in zip(gb.groups.keys(), gb.groups)\n",
    "        ]\n",
    "        \n",
    "        return groups\n",
    "    \n",
    "    def _create_tf_example(self, group, label_map):\n",
    "        \"\"\"Convert an images and respective annotation\n",
    "        to TFR Record (a binary file formata)\n",
    "        \n",
    "        Arguments:\n",
    "            group = pandas data frame\n",
    "            label_map = dict\n",
    "        \"\"\"\n",
    "        \n",
    "        # Serialize Image\n",
    "        with tf.gfile.GFile(os.path.join(\n",
    "            self.images_path, \"{}\".format(group.filename)), \"rb\") as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "            \n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "\n",
    "        filename = group.filename.encode(\"utf8\")\n",
    "        image_format = b\"jpg\"\n",
    "        \n",
    "        # check if the image format is matching with your images.\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "        \n",
    "        # Serialize XML annotation\n",
    "        for index, row in group.object.iterrows():\n",
    "            xmins.append(row[\"xmin\"] / width)\n",
    "            xmaxs.append(row[\"xmax\"] / width)\n",
    "            ymins.append(row[\"ymin\"] / height)\n",
    "            ymaxs.append(row[\"ymax\"] / height)\n",
    "            classes_text.append(row[\"class\"].encode(\"utf8\"))\n",
    "            class_index = label_map.get(row[\"class\"])\n",
    "            assert (\n",
    "                class_index is not None\n",
    "            ), \"class label: `{}` not found in label_map: {}\".format(\n",
    "                row[\"class\"], label_map\n",
    "            )\n",
    "            classes.append(class_index)\n",
    "        \n",
    "        # Create Tf Record\n",
    "        tf_example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature={\n",
    "                    \"image/height\": dataset_util.int64_feature(height),\n",
    "                    \"image/width\": dataset_util.int64_feature(width),\n",
    "                    \"image/filename\": dataset_util.bytes_feature(filename),\n",
    "                    \"image/source_id\": dataset_util.bytes_feature(filename),\n",
    "                    \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
    "                    \"image/format\": dataset_util.bytes_feature(image_format),\n",
    "                    \"image/object/bbox/xmin\": dataset_util.float_list_feature(xmins),\n",
    "                    \"image/object/bbox/xmax\": dataset_util.float_list_feature(xmaxs),\n",
    "                    \"image/object/bbox/ymin\": dataset_util.float_list_feature(ymins),\n",
    "                    \"image/object/bbox/ymax\": dataset_util.float_list_feature(ymaxs),\n",
    "                    \"image/object/class/text\": dataset_util.bytes_list_feature(\n",
    "                        classes_text\n",
    "                    ),\n",
    "                    \"image/object/class/label\": dataset_util.int64_list_feature(classes),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, group):\n",
    "    data = namedtuple(\"data\", [\"filename\", \"object\"])\n",
    "    gb = df.groupby(group)\n",
    "    return [\n",
    "        data(filename, gb.get_group(x))\n",
    "        for filename, x in zip(gb.groups.keys(), gb.groups)\n",
    "    ]\n",
    "\n",
    "def create_tf_example(group, path, label_map):\n",
    "    with tf.gfile.GFile(os.path.join(path, \"{}\".format(group.filename)), \"rb\") as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode(\"utf8\")\n",
    "    image_format = b\"jpg\"\n",
    "    # check if the image format is matching with your images.\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row[\"xmin\"] / width)\n",
    "        xmaxs.append(row[\"xmax\"] / width)\n",
    "        ymins.append(row[\"ymin\"] / height)\n",
    "        ymaxs.append(row[\"ymax\"] / height)\n",
    "        classes_text.append(row[\"class\"].encode(\"utf8\"))\n",
    "        class_index = label_map.get(row[\"class\"])\n",
    "        assert (\n",
    "            class_index is not None\n",
    "        ), \"class label: `{}` not found in label_map: {}\".format(\n",
    "            row[\"class\"], label_map\n",
    "        )\n",
    "        classes.append(class_index)\n",
    "\n",
    "    tf_example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image/height\": dataset_util.int64_feature(height),\n",
    "                \"image/width\": dataset_util.int64_feature(width),\n",
    "                \"image/filename\": dataset_util.bytes_feature(filename),\n",
    "                \"image/source_id\": dataset_util.bytes_feature(filename),\n",
    "                \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
    "                \"image/format\": dataset_util.bytes_feature(image_format),\n",
    "                \"image/object/bbox/xmin\": dataset_util.float_list_feature(xmins),\n",
    "                \"image/object/bbox/xmax\": dataset_util.float_list_feature(xmaxs),\n",
    "                \"image/object/bbox/ymin\": dataset_util.float_list_feature(ymins),\n",
    "                \"image/object/bbox/ymax\": dataset_util.float_list_feature(ymaxs),\n",
    "                \"image/object/class/text\": dataset_util.bytes_list_feature(\n",
    "                    classes_text\n",
    "                ),\n",
    "                \"image/object/class/label\": dataset_util.int64_list_feature(classes),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    filename  width  height   class  xmin  ymin  xmax  ymax\n",
      "133    1.png    700     700  f1_car    32   399   350   528\n",
      "134    1.png    700     700  f1_car   214   395   540   501\n"
     ]
    }
   ],
   "source": [
    "for group in grouped:\n",
    "    print(group[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.png</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>f1_car</td>\n",
       "      <td>114</td>\n",
       "      <td>365</td>\n",
       "      <td>467</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.png</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>f1_car</td>\n",
       "      <td>376</td>\n",
       "      <td>338</td>\n",
       "      <td>574</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.png</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>f1_car</td>\n",
       "      <td>554</td>\n",
       "      <td>289</td>\n",
       "      <td>669</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.png</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>f1_car</td>\n",
       "      <td>271</td>\n",
       "      <td>441</td>\n",
       "      <td>408</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.png</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>f1_car</td>\n",
       "      <td>166</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  width  height   class  xmin  ymin  xmax  ymax\n",
       "0   88.png    700     700  f1_car   114   365   467   668\n",
       "1   88.png    700     700  f1_car   376   338   574   501\n",
       "2   88.png    700     700  f1_car   554   289   669   393\n",
       "3   63.png    700     700  f1_car   271   441   408   588\n",
       "4   63.png    700     700  f1_car   166   209   208   249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
