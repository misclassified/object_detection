{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code we will randomnly split the raw images we have collected into train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 100 items\n"
     ]
    }
   ],
   "source": [
    "path_img = 'data/raw_images'\n",
    "files = os.listdir(path_img)\n",
    "# Make sure you only have .png images\n",
    "files = list(filter(lambda x: x.find('.png') != -1, files))\n",
    "\n",
    "print('We have a total of {} items'.format(len(files)))\n",
    "\n",
    "# Set parameters for train, validation and test\n",
    "train_size = 75\n",
    "test_size = 10\n",
    "validation_size = 10\n",
    "\n",
    "# Create sets\n",
    "train_files = np.random.choice(files, train_size, replace = False)\n",
    "remaining_files = list(set(files).difference(set(train_files)))\n",
    "\n",
    "test_files = np.random.choice(remaining_files, test_size, replace = False)\n",
    "remaining_files = list(set(remaining_files).difference(set(test_files)))\n",
    "\n",
    "validation_files = list(remaining_files)\n",
    "\n",
    "assert len(train_files) + len(test_files) + len(validation_files) == len(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize each image and place in the respective folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/raw_images'\n",
    "\n",
    "test_path = 'data/images/test'\n",
    "train_path = 'data/images/train'\n",
    "validation_path = 'data/images/validation'\n",
    "\n",
    "size = (700,700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE*: Out images are all named as \"img1.png\", \"img20.png\", etc, with the the 'img' preceding a number. We will strip the initial part of the name in the resize_and_rename function and rename the image as \"1.png\", \"20.png\". If you reuse the code you'll need to tweak the ```img_id = fname.split(\".\")[0][3:]``` step in the resize_and_rename function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rename(input_path, output_path, fname, size):\n",
    "    \"\"\"Resize and rename an image, formatting as png\n",
    "    \n",
    "    Arguments:\n",
    "        input_path = str\n",
    "        output_path = str\n",
    "        fname = str, file name\n",
    "        size = tuple of integers.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Read Image\n",
    "        img = cv2.imread(os.path.join(path_img, fname))\n",
    "        \n",
    "        # Resize \n",
    "        resized = cv2.resize(img, size)\n",
    "        \n",
    "        # Get image ID name\n",
    "        img_id = fname.split(\".\")[0][3:]\n",
    "        new_fname = \"{}.{}\".format(img_id, 'png')\n",
    "        \n",
    "        # Write Resized Image to Path\n",
    "        small_fname = os.path.join(output_path, new_fname)\n",
    "        cv2.imwrite(small_fname, resized)\n",
    "        \n",
    "    except:\n",
    "        print('Error with file: ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Path\n",
    "input_path = 'data/raw_images'\n",
    "\n",
    "# Define Output Paths\n",
    "test_path = 'data/images/test'\n",
    "train_path = 'data/images/train'\n",
    "validation_path = 'data/images/validation'\n",
    "\n",
    "# Define Size\n",
    "size = (700,700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Processing Train Files\n",
      "Started Processing Test Files\n",
      "Started Processing Evalution Files\n"
     ]
    }
   ],
   "source": [
    "# Process Train Set Images\n",
    "print(\"Started Processing Train Files\")\n",
    "for fname in train_files:\n",
    "    resize_and_rename(input_path, train_path, fname, size)\n",
    "    \n",
    "# Process Test Set Images\n",
    "print(\"Started Processing Test Files\")\n",
    "for fname in test_files:\n",
    "    resize_and_rename(input_path, test_path, fname, size)\n",
    "    \n",
    "# Process Evalution Set Images\n",
    "print(\"Started Processing Evalution Files\")\n",
    "for fname in validation_files:\n",
    "    resize_and_rename(input_path, validation_path, fname, size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
